{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4143a9b",
   "metadata": {},
   "source": [
    "# The Task At Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4feaa2b",
   "metadata": {},
   "source": [
    "In this Jupyter notebook I will be completing the City-Hive exercise that has been handed to me. This project at the time of completion will be able to:\n",
    "\n",
    "1)Upload a dataset containing corona statistics from a CSV format into a PostgreSQL database.\n",
    "\n",
    "2)Run a query that answers the following question and export its result into a csv file: How many countries does the dataset include?\n",
    "\n",
    "3)Upload that csv file into an AWS S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b97ef",
   "metadata": {},
   "source": [
    "# Plan of Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213549fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6cca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 version:    2.9.3 (dt dec pq3 ext lo64)\n",
      "sqlalchemy version:                          1.4.7\n",
      "pandas version:                          1.2.4\n",
      "selenium version:                          4.1.0\n",
      "urllib version:                            3.8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import psycopg2\n",
    "except:\n",
    "    !pip3 install psycopg2\n",
    "    import psycopg2\n",
    "print(\"psycopg2 version: {:>30}\".format(psycopg2.__version__))\n",
    "\n",
    "try:\n",
    "    import sqlalchemy\n",
    "except:\n",
    "    !pip3 install sqlalchemy\n",
    "    import sqlalchemy\n",
    "print(\"sqlalchemy version: {:>30}\".format(sqlalchemy.__version__))\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip3 install pandas\n",
    "    import pandas\n",
    "print(\"pandas version: {:>30}\".format(pandas.__version__))\n",
    "\n",
    "try:\n",
    "    import selenium\n",
    "except:\n",
    "    !pip3 install selenium\n",
    "    import selenium\n",
    "print(\"selenium version: {:>30}\".format(selenium.__version__))\n",
    "\n",
    "try:\n",
    "    import urllib.request\n",
    "except:\n",
    "    !pip3 install urllib.request\n",
    "    import urllib.request\n",
    "print(\"urllib version: {:>30}\".format(urllib.request.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d5db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://covid.ourworldindata.org/data/owid-covid-data.csv\n"
     ]
    }
   ],
   "source": [
    "#getting the URL of the hyperlink to download the CSV file\n",
    "import re \n",
    "\n",
    "html = urllib.request.urlopen(\"https://ourworldindata.org/covid-deaths\")\n",
    "text = html.read()\n",
    "plaintext = text.decode('utf8')\n",
    "links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", plaintext)\n",
    "csv_link = [link for link in links if \"csv\" in link]\n",
    "print(csv_link[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7d56aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CoronaStats.csv', <http.client.HTTPMessage at 0x205d9535f10>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading and saving the dataset from the link\n",
    "from urllib.request import urlretrieve as retrieve\n",
    "\n",
    "retrieve(csv_link[0], 'CoronaStats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a198604d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is A60F-1A98\n",
      "\n",
      " Directory of C:\\Users\\gavis\n",
      "\n",
      "26/01/2022  20:45    <DIR>          .\n",
      "26/01/2022  20:45    <DIR>          ..\n",
      "19/11/2020  01:19    <DIR>          .android\n",
      "26/01/2022  20:47    <DIR>          .conda\n",
      "20/09/2021  12:11                25 .condarc\n",
      "20/09/2021  12:11    <DIR>          .continuum\n",
      "21/03/2021  18:26    <DIR>          .dotnet\n",
      "20/01/2022  00:31    <DIR>          .idlerc\n",
      "26/01/2022  14:50    <DIR>          .ipynb_checkpoints\n",
      "20/09/2021  12:16    <DIR>          .ipython\n",
      "11/10/2021  11:26    <DIR>          .jupyter\n",
      "12/10/2021  10:58    <DIR>          .keras\n",
      "13/10/2021  18:31    <DIR>          .matplotlib\n",
      "13/12/2021  18:13    <DIR>          .nbi\n",
      "22/03/2021  13:20    <DIR>          .nuget\n",
      "25/12/2019  02:06    <DIR>          .Origin\n",
      "26/01/2022  14:43                65 .pgAdmin4.1057243102.addr\n",
      "26/01/2022  15:29             1,066 .pgAdmin4.1057243102.log\n",
      "26/01/2022  14:43             1,580 .pgAdmin4.startup.log\n",
      "09/02/2020  02:09    <DIR>          .PyCharmCE2019.3\n",
      "25/12/2019  02:06    <DIR>          .QtWebEngineProcess\n",
      "17/03/2021  12:16    <DIR>          3D Objects\n",
      "08/01/2020  00:11         2,700,716 AMD_RyzenMaster.log\n",
      "08/01/2020  00:11             2,779 AMDRM_Install.log\n",
      "20/01/2022  00:51    <DIR>          anaconda3\n",
      "11/01/2020  19:31    <DIR>          cdssetup\n",
      "17/03/2021  12:16    <DIR>          Contacts\n",
      "26/01/2022  20:45             4,365 Corona Countries.ipynb\n",
      "26/01/2022  20:35        44,541,750 CoronaStats.csv\n",
      "23/09/2021  15:09            60,142 Data Science Project  final proposition\n",
      "10/10/2021  18:17           115,003 Data Science Project .ipynb\n",
      "24/12/2019  15:12    <DIR>          Documents\n",
      "24/01/2022  19:54    <DIR>          Downloads\n",
      "17/03/2021  12:16    <DIR>          Favorites\n",
      "26/01/2022  19:39                 0 geckodriver.log\n",
      "19/01/2022  23:53         2,159,352 get-pip.py\n",
      "09/10/2021  22:02        24,690,918 jupyter project\n",
      "17/03/2021  12:16    <DIR>          Links\n",
      "17/03/2021  12:16    <DIR>          Music\n",
      "13/08/2020  15:50    <DIR>          New Folder\n",
      "09/08/2021  15:41    <DIR>          OneDrive\n",
      "19/01/2022  22:03    <DIR>          PycharmProjects\n",
      "10/10/2021  17:20               295 requirements.txt\n",
      "17/03/2021  12:16    <DIR>          Saved Games\n",
      "17/03/2021  12:16    <DIR>          Searches\n",
      "24/02/2020  01:10    <DIR>          source\n",
      "11/11/2021  11:48    <DIR>          Tracing\n",
      "10/10/2021  18:10               917 Untitled.ipynb\n",
      "21/07/2021  14:37    <DIR>          Videos\n",
      "              15 File(s)     74,278,973 bytes\n",
      "              34 Dir(s)  62,682,443,776 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef8c88",
   "metadata": {},
   "source": [
    "## Create a SQL statement to create our database table so that we can import the csv we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c31451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases', 'new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions', 'weekly_hosp_admissions_per_million', 'new_tests', 'total_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'total_boosters', 'new_vaccinations', 'new_vaccinations_smoothed', 'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred', 'new_vaccinations_smoothed_per_million', 'new_people_vaccinated_smoothed', 'new_people_vaccinated_smoothed_per_hundred', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index', 'excess_mortality_cumulative_absolute', 'excess_mortality_cumulative', 'excess_mortality', 'excess_mortality_cumulative_per_million']\n"
     ]
    }
   ],
   "source": [
    "#use pandas to get names of coloumns of the csv\n",
    "import os\n",
    "import pandas as pd\n",
    "ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "csv_file_path = ipynb_path + '\\\\CoronaStats.csv' \n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "column_names = list(csv_data.columns.values)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48ca49",
   "metadata": {},
   "source": [
    "### As you can see here, our csv is the correct one as shown in the 5 first columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a786a655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "1             NaN           NaN                  37.746   \n",
       "2             NaN           NaN                  37.746   \n",
       "3             NaN           NaN                  37.746   \n",
       "4             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "1                         0.5            64.83                    0.511   \n",
       "2                         0.5            64.83                    0.511   \n",
       "3                         0.5            64.83                    0.511   \n",
       "4                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197a465",
   "metadata": {},
   "source": [
    "## Now lets build our SQL statement:\n",
    "To do so we will join the column name with the data type it needs when defining a table, and then add a comma between each line. Now because the data type names are different in pandas than SQL, we shall make a dictionary to replace each column data type in pandas to the correct type name in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e63bb989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_code varchar, continent varchar, location varchar, date varchar, total_cases float, new_cases float, new_cases_smoothed float, total_deaths float, new_deaths float, new_deaths_smoothed float, total_cases_per_million float, new_cases_per_million float, new_cases_smoothed_per_million float, total_deaths_per_million float, new_deaths_per_million float, new_deaths_smoothed_per_million float, reproduction_rate float, icu_patients float, icu_patients_per_million float, hosp_patients float, hosp_patients_per_million float, weekly_icu_admissions float, weekly_icu_admissions_per_million float, weekly_hosp_admissions float, weekly_hosp_admissions_per_million float, new_tests float, total_tests float, total_tests_per_thousand float, new_tests_per_thousand float, new_tests_smoothed float, new_tests_smoothed_per_thousand float, positive_rate float, tests_per_case float, tests_units varchar, total_vaccinations float, people_vaccinated float, people_fully_vaccinated float, total_boosters float, new_vaccinations float, new_vaccinations_smoothed float, total_vaccinations_per_hundred float, people_vaccinated_per_hundred float, people_fully_vaccinated_per_hundred float, total_boosters_per_hundred float, new_vaccinations_smoothed_per_million float, new_people_vaccinated_smoothed float, new_people_vaccinated_smoothed_per_hundred float, stringency_index float, population float, population_density float, median_age float, aged_65_older float, aged_70_older float, gdp_per_capita float, extreme_poverty float, cardiovasc_death_rate float, diabetes_prevalence float, female_smokers float, male_smokers float, handwashing_facilities float, hospital_beds_per_thousand float, life_expectancy float, human_development_index float, excess_mortality_cumulative_absolute float, excess_mortality_cumulative float, excess_mortality float, excess_mortality_cumulative_per_million float\n"
     ]
    }
   ],
   "source": [
    "\n",
    "replacements = {\n",
    "        'timedelta64[ns]': 'varchar',\n",
    "        'object': 'varchar',\n",
    "        'float64': 'float',\n",
    "        'int64': 'int',\n",
    "        'datetime64': 'timestamp'\n",
    "}\n",
    "\n",
    "col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(column_names, csv_data.dtypes.replace(replacements)))\n",
    "print(col_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81953e",
   "metadata": {},
   "source": [
    "# Establish a connection to our database\n",
    "I made a database using the AWS RDS infastructure with a PostgreSQL engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "040e07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened database succesfully\n"
     ]
    }
   ],
   "source": [
    "conn_string = \"host=coronastatistics.cz9th7gv5riq.us-east-1.rds.amazonaws.com \\\n",
    "                dbname=''\\\n",
    "                user='postgres' password='Password'\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cursor = conn.cursor()\n",
    "print(\"opened database succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1858c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table\n",
    "full_sql_query = \"create table coronadata\" + '(' + col_str + ')' \n",
    "cursor.execute(full_sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7856987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file copied to db\n"
     ]
    }
   ],
   "source": [
    "#copying the data from the csv file to the database\n",
    "my_file = open(csv_file_path)\n",
    "SQL_STATEMENT = \"\"\"\n",
    "COPY coronadata FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    " \"\"\"\n",
    "cursor.copy_expert(sql = SQL_STATEMENT, file = my_file)\n",
    "print(\"file copied to db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9f4daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table coronadata imported to db completed\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"grant select on table coronadata to public\")\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print(\"table coronadata imported to db completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517b217",
   "metadata": {},
   "source": [
    "# Run The Query and save the results in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6fa68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
