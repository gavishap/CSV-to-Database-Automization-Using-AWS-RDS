{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfa521a",
   "metadata": {},
   "source": [
    "# The Task At Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a615ed",
   "metadata": {},
   "source": [
    "In this Jupyter notebook I will be completing the City-Hive exercise that has been handed to me. This project at the time of completion will be able to:\n",
    "\n",
    "1)Upload a dataset from a website containing corona statistics from a CSV format into a AWS database of PostgreSQL format.\n",
    "\n",
    "2)Run a query that answers the following question and export its result into a csv file: How many countries does the dataset include?\n",
    "\n",
    "3)Upload that csv file into an AWS S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc01bc6",
   "metadata": {},
   "source": [
    "# Plan of Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61c37f",
   "metadata": {},
   "source": [
    "*Step 1*\n",
    "\n",
    "    A) Import all the packages needed for this project\n",
    "    B) Get the URL of the hyperlink that needs to clicked in order to download the dataset\n",
    "    C) Download the dataset and save it to our directory\n",
    "    D) Create an SQL statement to give to our AWS databse to create our table\n",
    "    E) Connect to our AWS database\n",
    "    F) Creat an empty table with the names of the columns in our database\n",
    "    G) Copy the rest of the data into the database\n",
    "\n",
    "*Step 2*\n",
    "\n",
    "    H) Make a pandas query function to give the results of the unique countries in the location column.\n",
    "    I) Save and export the results of the query into our working directory\n",
    "    \n",
    "*Step 3*\n",
    "\n",
    "    J) Connect to the S3 bucket I made\n",
    "    K) Upload the CSV file to the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134d9e7",
   "metadata": {},
   "source": [
    "## A)Import all the packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9842021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 version:    2.9.3 (dt dec pq3 ext lo64)\n",
      "pandas version:                          1.2.4\n",
      "urllib version:                            3.8\n",
      "boto3 version:                        1.18.65\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import psycopg2\n",
    "except:\n",
    "    !pip3 install psycopg2\n",
    "    import psycopg2\n",
    "print(\"psycopg2 version: {:>30}\".format(psycopg2.__version__))\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip3 install pandas\n",
    "    import pandas\n",
    "print(\"pandas version: {:>30}\".format(pandas.__version__))\n",
    "\n",
    "try:\n",
    "    import urllib.request\n",
    "except:\n",
    "    !pip3 install urllib.request\n",
    "    import urllib.request\n",
    "print(\"urllib version: {:>30}\".format(urllib.request.__version__))\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "except:\n",
    "    !pip3 install boto3\n",
    "    import boto3\n",
    "print(\"boto3 version: {:>30}\".format(boto3.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59cdaa",
   "metadata": {},
   "source": [
    "## B) Get the URL of the hyperlink that needs to clicked in order to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad4f0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://covid.ourworldindata.org/data/owid-covid-data.csv\n"
     ]
    }
   ],
   "source": [
    "#getting the URL of the hyperlink to download the CSV file\n",
    "import re \n",
    "\n",
    "html = urllib.request.urlopen(\"https://ourworldindata.org/covid-deaths\")\n",
    "text = html.read()\n",
    "plaintext = text.decode('utf8')\n",
    "links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", plaintext)\n",
    "csv_link = [link for link in links if \"csv\" in link]\n",
    "print(csv_link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a44e1a",
   "metadata": {},
   "source": [
    "## C)Download the dataset and save it to our directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220c419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CoronaStats.csv', <http.client.HTTPMessage at 0x205d9535f10>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading and saving the dataset from the link\n",
    "from urllib.request import urlretrieve as retrieve\n",
    "\n",
    "retrieve(csv_link[0], 'CoronaStats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea5855",
   "metadata": {},
   "source": [
    "## D) Create a SQL statement to create our database table so that we can import the csv we downloaded\n",
    "\n",
    "To do so we will get the names of the columns and then join the column name with the correct data type it needs when defining a table. After that add a comma between each line. Now because the data type names are different in pandas than SQL, we shall make a dictionary to replace each column data type in pandas to the correct type name in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4330d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases', 'new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions', 'weekly_hosp_admissions_per_million', 'new_tests', 'total_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'total_boosters', 'new_vaccinations', 'new_vaccinations_smoothed', 'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred', 'new_vaccinations_smoothed_per_million', 'new_people_vaccinated_smoothed', 'new_people_vaccinated_smoothed_per_hundred', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index', 'excess_mortality_cumulative_absolute', 'excess_mortality_cumulative', 'excess_mortality', 'excess_mortality_cumulative_per_million']\n"
     ]
    }
   ],
   "source": [
    "#use pandas to get names of coloumns of the csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "csv_file_path = ipynb_path + '\\\\CoronaStats.csv' \n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "column_names = list(csv_data.columns.values)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fa8c2",
   "metadata": {},
   "source": [
    "### As you can see here, our csv is the correct one as shown in the 5 first columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b8303ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "1             NaN           NaN                  37.746   \n",
       "2             NaN           NaN                  37.746   \n",
       "3             NaN           NaN                  37.746   \n",
       "4             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "1                         0.5            64.83                    0.511   \n",
       "2                         0.5            64.83                    0.511   \n",
       "3                         0.5            64.83                    0.511   \n",
       "4                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c6b91f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_code varchar, continent varchar, location varchar, date varchar, total_cases float, new_cases float, new_cases_smoothed float, total_deaths float, new_deaths float, new_deaths_smoothed float, total_cases_per_million float, new_cases_per_million float, new_cases_smoothed_per_million float, total_deaths_per_million float, new_deaths_per_million float, new_deaths_smoothed_per_million float, reproduction_rate float, icu_patients float, icu_patients_per_million float, hosp_patients float, hosp_patients_per_million float, weekly_icu_admissions float, weekly_icu_admissions_per_million float, weekly_hosp_admissions float, weekly_hosp_admissions_per_million float, new_tests float, total_tests float, total_tests_per_thousand float, new_tests_per_thousand float, new_tests_smoothed float, new_tests_smoothed_per_thousand float, positive_rate float, tests_per_case float, tests_units varchar, total_vaccinations float, people_vaccinated float, people_fully_vaccinated float, total_boosters float, new_vaccinations float, new_vaccinations_smoothed float, total_vaccinations_per_hundred float, people_vaccinated_per_hundred float, people_fully_vaccinated_per_hundred float, total_boosters_per_hundred float, new_vaccinations_smoothed_per_million float, new_people_vaccinated_smoothed float, new_people_vaccinated_smoothed_per_hundred float, stringency_index float, population float, population_density float, median_age float, aged_65_older float, aged_70_older float, gdp_per_capita float, extreme_poverty float, cardiovasc_death_rate float, diabetes_prevalence float, female_smokers float, male_smokers float, handwashing_facilities float, hospital_beds_per_thousand float, life_expectancy float, human_development_index float, excess_mortality_cumulative_absolute float, excess_mortality_cumulative float, excess_mortality float, excess_mortality_cumulative_per_million float\n"
     ]
    }
   ],
   "source": [
    "#type replacement dictionary\n",
    "replacements = {\n",
    "        'timedelta64[ns]': 'varchar',\n",
    "        'object': 'varchar',\n",
    "        'float64': 'float',\n",
    "        'int64': 'int',\n",
    "        'datetime64': 'timestamp'\n",
    "}\n",
    "\n",
    "col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(column_names, csv_data.dtypes.replace(replacements)))\n",
    "print(col_str)\n",
    "#You see from here that we have built the inside of the table with the right types nest to each column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de18a3",
   "metadata": {},
   "source": [
    "## E) Connect to our AWS database\n",
    "I made a database using the AWS RDS infastructure with a PostgreSQL engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6dc4f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened database succesfully\n"
     ]
    }
   ],
   "source": [
    "conn_string = \"host=coronastatistics.cz9th7gv5riq.us-east-1.rds.amazonaws.com \\\n",
    "                dbname=''\\\n",
    "                user='postgres' password='Password'\"\n",
    "try:\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"opened database succesfully\")\n",
    "except:\n",
    "    print(\"Unable to connect to database\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e10b97",
   "metadata": {},
   "source": [
    "## F) Creat an empty table with the names of the columns in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db89d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table without data\n",
    "full_sql_query = \"create table coronadata\" + '(' + col_str + ')' \n",
    "cursor.execute(full_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304033a",
   "metadata": {},
   "source": [
    "## G) Copy the rest of the data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87f3278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file copied to db\n"
     ]
    }
   ],
   "source": [
    "#copying the data from the csv file to the database\n",
    "try:\n",
    "    my_file = open(csv_file_path)\n",
    "except:\n",
    "    print(\"Could not open csv file\")\n",
    "SQL_STATEMENT = \"\"\"\n",
    "COPY coronadata FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    " \"\"\"\n",
    "try:\n",
    "    cursor.copy_expert(sql = SQL_STATEMENT, file = my_file)\n",
    "    print(\"file copied to db\")\n",
    "except:\n",
    "    print(\"Could not copy data into database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed092de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table coronadata imported to db completed\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"grant select on table coronadata to public\")\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print(\"table coronadata imported to db completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5e508",
   "metadata": {},
   "source": [
    "## H) Make a pandas query function to give the results of the unique countries in the location column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "793cf567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238\n"
     ]
    }
   ],
   "source": [
    "#run a pandas query on the data to find unique countries number\n",
    "country_count = csv_data['location'].nunique()\n",
    "print(country_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfdddd",
   "metadata": {},
   "source": [
    "## I) Save and export the results of the query into our working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ada82861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count\n",
      "0    238\n"
     ]
    }
   ],
   "source": [
    "#create pandas table that holds the distinct country count\n",
    "distinct_countries = {'count' : [country_count]}\n",
    "distinct_countries_df = pd.DataFrame(distinct_countries)\n",
    "print (distinct_countries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d554bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export it to where our code is running\n",
    "with open(\"count_countries.csv\", \"w\") as count_countries:\n",
    "    distinct_countries_df.to_csv(count_countries, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b8ff1",
   "metadata": {},
   "source": [
    "## J) Connect to the S3 bucket I made\n",
    "## K) Upload the CSV file to the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3f21eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file uploaded to Bucket succesfully\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "#made a special user that has access to the s3 bucket\n",
    "access_key='AKIATXLDSL5MH2CGKUHE'\n",
    "secret_access_key='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'\n",
    "\n",
    "#connect to the s3 bucket\n",
    "client = boto3.client('s3', aws_access_key_id = access_key , aws_secret_access_key = secret_access_key)\n",
    "\n",
    "#search through directory and find the CSV file we saved and upload it to s3\n",
    "for file in os.listdir():\n",
    "    if 'count_countries.csv' in file:\n",
    "        upload_file_bucket = 'city-hive-exercise-bucket'\n",
    "        upload_file_key = 'coronastats' + str(file)\n",
    "        client.upload_file(file, upload_file_bucket, upload_file_key)\n",
    "        break\n",
    "print(\"CSV file uploaded to Bucket succesfully\")\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
